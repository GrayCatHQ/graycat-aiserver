version: "3.9"

services:
  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --requirepass "${REDIS_PASS}" --timeout 0
    environment:
      - REDIS_PASS=${REDIS_PASS}
    ports:
      - "6379:6379"
    restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: llama_api
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379
      - REDIS_PASS=${REDIS_PASS}
      - API_TOKENS=${API_TOKENS}
    ports:
      - "8000:8000"
    restart: unless-stopped

  # gpu-worker:
  #   build:
  #     context: ./gpu
  #     dockerfile: Dockerfile
  #   container_name: llama_worker
  #   ports: 
  #     - "50018:50018"
  #   environment:
  #     - REDIS_HOST=redis
  #     - REDIS_PASS=${REDIS_PASS}
  #     - LLAMA_SERVER_URL=${LLAMA_SERVER_URL}
  #   # if you mount your model directory:
  #   restart: unless-stopped
  #   volumes:
  #     - ./gpu/models:/app/models
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]

  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs/nginx:/var/log/nginx
    restart: unless-stopped
    depends_on:
      - api
