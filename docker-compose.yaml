version: "3.9"

services:
  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --requirepass "${REDIS_PASS}" --timeout 0
    environment:
      - REDIS_PASS=${REDIS_PASS}
    ports:
      - "6379:6379"
    restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: llama_api
    depends_on:
      - redis
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PASS=${REDIS_PASS}
      - API_TOKENS=${API_TOKENS}
    ports:
      - "8000:8000"
    restart: unless-stopped

  gpu:
    build:
      context: ./gpu
      dockerfile: Dockerfile
    container_name: llama_worker
    ports: 
      - "1337:1337"
      - "7860:7860"
    environment:
      - GPU_LAYERS=${GPU_LAYERS}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PASS=${REDIS_PASS}
      - LLAMA_SERVER_URL=${LLAMA_SERVER_URL}
      - REMOTE=${REMOTE}
      - MODEL_URL=${MODEL_URL}
      - PORT=${PORT}
      - RUN_SD=${RUN_SD}
    # if you mount your model directory:
    restart: unless-stopped
    volumes:
      - ./gpu/data:/app/data
    depends_on:
      - api
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # nginx:
  #   image: nginx:alpine
  #   container_name: nginx
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #     - ./nginx/logs/nginx:/var/log/nginx
  #   restart: unless-stopped
  #   depends_on:
  #     - api
